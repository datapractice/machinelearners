\chapter{Machines finding functions}
\label{ch:function}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  warning=FALSE, message=FALSE, dev='pdf')

library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
```

> Because of a gradient that no doubt characterizes our cultures, discursive formations are constantly becoming epistemologized [@Foucault_1972, 195]

The opening pages of machine learning textbooks often warn or enthuse about the profusion of techniques, algorithms, tools and machines. \index{machine learners!variety of|(} 'The first problem facing you', writes Pedro Domingos, 'is the bewildering variety of learning algorithms available. Which one to use? There are literally thousands available, and hundreds more are published each year [@Domingos_2012, 1]. \index{Domingos, Pedro} 'The literature on machine learning is vast, as is the overlap with the relevant areas of statistics and engineering' writes David Barber in _Bayesian Reasoning and Machine Learning_[@Barber_2011,4]; 'statistical learning refers to a vast set of tools for understanding data' writes James and co-authors in an _Introduction to Statistical Learning with R_ [@James_2013,1]; or writing in in *Statistical Learning for Biomedical Data* the biostatisticians James Malley, Karen Malley and Sinisa Pajevic 'freely admit that many machines studied in this text are somewhat mysterious, though powerful engines'  [@Malley_2011,  257]. In _Thoughtful Machine Learning_ Matthew Kirk adds: 'flexibility is also what makes machine learning daunting. It can solve many problems, but how do we know whether we’re solving the right problem, or actually solving it in the first place?' [@Kirk_2014, ix]. \index{Kirk, Matthew}  The prefatory comments from Domingos, Barber, James, Malley and Kirk suggest  that machine learning comprises a rampant abundance of techniques. Much machine learning work, at least for many practitioners, concerns not so much implementation of particular techniques (neural network, decision tree, support vector machine, logistic regression, etc.), but rather navigating the maze of methods and variations that might be relevant to a particular situation. 

\begin{figure}
  \centering
      \includegraphics[width=0.95\textwidth]{figure/ml_map_scikit.pdf}
        \caption{`scikit-learn` map of machine learning techniques [TBA: ref to diagram]}
  \label{fig:mapping_functions}
\end{figure}

How does this effect of accumulation and profusion arise and what do machine learners do about it? The publications I have just been referring to attempt to both present that profusion as a problem of publications and to manage it by writing textbooks that provide indexes, maps and guides to the bewildering variety of machine learners. The anchoring textbook _Elements of Statistical Learning_ deploys tables, overviews, theories of statistical modelling, model assessment and comparison techniques to aid in navigating them. Parallel and complementary mappings accompany software libraries. The map of machine learning techniques shown in Figure \ref{fig:mapping_functions} comes from a particular software library written in `Python,` `scikit-learn` [@Pedregosa_2011].  \index{Python!scikit-learn library} This software library is widely used in industry, research and commerce. In contrast to the pedagogical expositions, theoretical accounts or guides to reference implementation, code libraries such as  `scikit-learn` tend to order the range of techniques by offering recipes and maps for the use of the *functions* the libraries supply. \index{function!code|(} The branches in the figure lay down paths through the profusion of techniques as a decision tree.[^3.01] Similarly, for `R` code, the *Comprehensive R Archive Network* tabulates key libraries of `R` code in  a  machine learning 'task view' [@Hothorn_2014].  
\index{machine learners!variety of|)}

```{r scikit-learn, engine='python', echo=TRUE, messages=FALSE, warnings=FALSE, results='asis'}
import sklearn
from sklearn import *
modules = dir(sklearn)
modules_clean = [m for m in modules if not m.startswith('_')]
print(modules_clean)
```

The architecture of these software libraries itself classifies and orders machine learners.  `Scikit-learn` for instance comprises a number of sub-packages:
Modules such as `lda` (linear discriminant analysis), `svm` (support vector machine) or `neighbors` (_k_ nearest neighbours) point to well-known machine learners, whilst `cross-validation` or `feature_selection` refer to ways of testing models or transforming data respectively. Again, machine learning patches together a variety of abstractive practices. \index{abstraction!levels of} These divisions, maps and classifications help order the techniques, but they obscure the problematic process that first generated a competing profusion of machine learners. That profusion comes from a slippage between two main senses of the function: function as mathematical relation and function as concrete machinic operation.  \index{function!code|)}

Machine learners find functions machinically. The primary mathematical sense of a function refers to a relation between sets of values or variables. (A variable is a symbol that can stand for a set of numbers or other values.) A function is one-to-one relation between two sets of values. It maps a set of arguments (inputs) to a set of values (outputs, or to use slightly more technical language, it maps between a _domain_ and a _co-domain_.) As we have already seen, mathematical functions are often written in formulae of varying degrees of complexity. They are of various genres, provenances, textures and shapes: polynomial functions, trigonometric functions, exponential functions, differential equations, series functions, algebraic or topological functions, etc. Various fields of mathematics have pursued the invention of functions. In machine learning and information retrieval, important functions would include the logistic function (discussed below), probability density functions (PDF) for different probability distributions (Gaussian, Bernoulli, Binomial, Beta, Gamma, etc.). \index{probability!distribution} \index{function!mathematical} From an _almost_ purely mathematical standpoint, machine learning can be understood as function finding operations. Implicitly or explicitly, machine learners find a mathematical expression -- a function -- approximating an outcome of the social, technical, financial, transactional, biological, brain, heart or group process that generated the data in question. Regardless of the application, no single mathematical function perfectly or uniques expresses data. Many if not infinite functions can approximate any given data. The abundance of functions blurs the diagonal lines that run between the mathematical function defined in an equation and an operational machine learner designed to find specific values of the parameters of that function. The mathematical function and the software function are in diagrammatic relation, but the _diagonals_ that run between them are not always in a one-to-one mapping. \index{diagrammatic!diagonal}

## Supervised or unsupervised, who learns what?

The `scikit-learn` map of techniques addresses the problem of choosing a machine learner. This is only a starting point. No matter how powerful machine learners become,  they do not operate autonomously.  The techniques, models, forms of abstraction, data formats, and performance properties of algorithms have to be learned by people (reading books, attending classes, watching demonstrations, trying out software and code, etc. See Chapter \ref{ch:subjects}). Once learned, maps such as the one shown in Figure \ref{fig:mapping_functions} may become redundant. But other forms of close attention, monitoring, and observation remain crucial whenever  machine learners encounter data or wherever they enter the common vector space. 

A need to observe the machine organises the field of machine learning. The optics of this observation of how machine learners traverse the common vector space vary. \index{common vector space} Machine learning textbooks and courses usually distinguish 'supervised', 'unsupervised' and sometimes 'semi-supervised' learning. While the field is almost despotically pragmatic in its commitment to optimisation of  classification and prediction (although in certain ways, curiously idealistic too in its constant reuse of well-worked datasets such as `iris` or `South African heart disease`), it reluctantly accepts the existence of these two broadly different kinds of _learning_. \index{machine learning!learning|(} Writing around 2000, Hastie et. al. state: 

>With supervised learning there is a clear measure of success or lack thereof, that can be used to judge adequacy in particular situations and to compare the effectiveness of different methods over various situations. Lack of success is directly measured by expected loss over the  joint distribution $Pr(X,Y)$. This can be estimated in a variety of ways including cross-validation. In the context of unsupervised learning, there is no such direct measure of success. ... This uncomfortable situation has led to heavy proliferation of proposed methods, since effectiveness is a matter of opinion and cannot be verified directly.  [@Hastie_2009, 486-7]

Supervised learning in general terms constructs a model by training it on some sample data (the training data \index{data!training} ), and then evaluating its effectiveness in classifying or predicting  test data \index{data!test} whose actual values are already known. The 'clear measure of success' they refer to in relation to in so-called 'supervised learning' is of relatively recent date.[^3.02]  Unsupervised machine learning techniques generally look for patterns in the data without any training or testing phases (for instance, _k_-means or principal component analysis do this, and both techniques have been heavily used for more than fifty years). In both supervised and unsupervised learning people look at the models to find out how the models traverse, fit, partition or map the data. At a general level, machine learning is a system of making statements and rendering relations visible through supervision. As I will suggest below, partial observers -- a term drawn from the work of Félix Guattari and Gilles Deleuze -- supervise the diagrammatic functioning of machine learning.   At the same time, opacity -- 'no direct measure of success' -- is generative in machine learning. \index{partial observer|see{function!partial observer}} Amidst the optically dense pages of mathematical functions, plots of datasets and listing of algorithms, _Elements of Statistical Learning_'s frank admission that something cannot be measured and that this difficulty has led to proliferating methods seems to me quite promising ground to explore for possible transformations and changes. But  this discomfort about unsupervised learning does seem to discourage its use.  If, as the first part of the quoted text puts it, supervised learning has a clear 'measure of success,' that success only seems to encourage further variations and comparisons that end up proliferating machine learners, their publications and their software implementations.  Levels of predictive success may vary widely with different techniques and different situations, but an almost unbounded optimism associated with machine learning (for instance as more or less unspoken foundation of  any analysis of 'big data')  runs pell-mell across all of them. \index{machine learning!learning|)}

## Which function operates?

\index{function!mathematical|(} Formally, the differences between machine learners appear as mathematical functions. The  mathematical sense of function is writ large in nearly all machine learning literature since functions diagram the relations on which devices and machines operate. Indeed, we might say that machine learning is nothing other than a machinic version of the functions that have long interested and occupied mathematicians. Importantly, functions support both the operations and the ordering of those operations.   Classifiers, or machine learners that allocate case to categories, are often identified directly with functions:

>A classifier or classification rule is a function $d(\mathbf{x})$ defined on $\mathcal{X}$ so that for every $\mathbf{x}$, $d(\mathbf{x})$ is equal to one of the numbers $1, 2, ..., J$ [@Breiman_1984, 4]

Writing in the 1980s, the statistician Leo Breiman describes classifiers -- perhaps the key technical achievement of machine learning and certainly the catalyst of many applications of machine learning  -- in terms of functions. A classifier _is_ a function $d(\mathbf(x)}$ where is $\mathbf{x}$ is the data and $d$ ranges over numbers that map onto categories, rankings or or other forms of order and belonging. The equation of machine learners  to functions is quite pervasive. \index{Breiman, Leo} Learning, predictions, and the classifications produced by machine learning derive from functions. The identification of machine learning with functions appears in the first pages of most machine learning textbooks. Learning in machine learning means finding a function that can identify or predict patterns in the data. As _Elements of Statistical Learning_ puts it,

>our goal is to find a useful approximation $\hat{f}(x)$ to the function $f(x)$ that underlies the predictive relationship between input and output [@Hastie_2009, 28]. 

In a highly compressed form, this statement of goals doubles the function. It contains _the_ function that generated the data as a foundation. This function figures as a ground truth imputed to the world. It also refers to 'finding  ... $\hat{f}(x)$', where the '^' indicates an approximation produced by an algorithmic implementations, and it avers to 'use'. Similar statements pile up in the literature. Perhaps more importantly, _learning_ here is understood as function finding. A leading theorist of learning theory Vladimir Vapnik again uses the language of approximation: 'learning is a problem of _function estimation_ on the basis of empirical data' [@Vapnik_1999, 291].[^3.03] \index{Vapnik, Vladimir}  The use of the term 'learning' in machine learning displays affiliations to the field of artificial intelligence, but the  attempt to find a 'useful approximation' -- the 'function-fitting paradigm' as [@Hastie_2009, 29] terms it -- stems mainly from statistics.  Not all accounts of machine learning emphasise learning as  function fitting. Some retain the language of intelligent machines (see for example, [@Alpaydin_2010, xxxvi] who writes: 'we do not need to come up with new algorithms if machines can learn themselves'). Despite any differences in the  framing of the techniques, all accounts of machine learning, even those such as _Machine Learning for Hackers_ [@Conway_2012] that eschew any explicit recourse to mathematical formula,  rely on the  formalism and modes of thought associated with mathematical functions. Whether they are seen as forms of artificial intelligence or statistical models, the formalisms are directed to build 'a good and useful approximation to the desired output' [@Alpaydin_2010, 41], or, put more statistically,  'to use the sample to find the function from the set of admissable functions that minimizes the probability of error' [@Vapnik_1999, 31]. Note the unobtrusive but crucial caveats in this formulation: functions must be found from a set of 'admissable functions.' Functions anchor machine learning so that we don't have to come up with algorithms, yet functions themselves have to be found under certain constraints.
\index{function!mathematical|)}

Which functions does machine learning admit? As is often the case in working with a massive technical literature, the first problem in making sense of what is happening with function in machine learning concerns sheer abundance. The pages of [@Hastie_2009] are marked with score of references to 'functions': quadratic function, likelihood function, sigmoid function, loss function, regression function, basis function, activation function, penalty functions, additive functions, kernel functions,step function,  error function, constraint function, discriminant function, probability density function, weight function, coordinate function, neighborhood function, and the list goes on. This list stands against a background of several hundred mathematical functions commonly used in science and engineering.[^3.05] Clearly we cannot expect to understand the functioning of all these functions in any great detail. However, even a glance through this prickly list of terms begins to suggest that not only is there quite a heavy reliance on functions in this field (as perhaps in many other science and engineering disciplines), but that the proliferation of functions might itself be a way to map some important  operations occurring in and around machine learning. We can also already see in this list that the qualifiers of the term function are diverse. Sometimes, the qualifier refers to a mathematical form -- 'quadratic,' 'coordinate', 'basis' or 'kernel'; sometimes it refers to statistical considerations -- 'likelihood', 'regression', 'error,' or 'probability density'; and sometimes it refers to some other concern that might relate to a particular modelling device or diagram -- 'activation,' 'weight', 'loss,'  'constraint,' or 'discriminant.' These multiple modes of functions matter, since they support and configure the different senses of mathematical, machinic and diagrammatic function-finding in machine learning. 

[^3.05]: The U.S. National Institute of Standards published *The Handbook of Mathematical Functions* in 1965 [@Abramowitz_1965]. This heavily cited volume, now also [versioned online](http://dlmf.nist.gov) lists hundreds of functions organised in various categories ranging from algebra to zeta functions. While a large number of the functions and operations catalogued there can be traced into machine learning, in many respects, machine learners implement, as we will see, quite a narrow range of functions. 



[^3.01]: See Chapter \ref{ch:pattern} for discussion of decision trees in machine learning.

[^3.02]:  Only in the mid-1980s were the first theories of algorithmic learning formalised [@Valiant_1984].

[^3.03]: Vapnik is said to have invented the support vector machine, one of the most heavily used machine learning technique of recent years on the basis of his theory of computational learning. Chapter \ref{ch:dimension} discusses the support vector machine.
